{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n完整版和简化版的区别是有两个value模型\\n还有动态调整alpha\\n其他的和简化版一样'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "完整版和简化版的区别是有两个value模型\n",
    "还有动态调整alpha\n",
    "其他的和简化版一样\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47837758, -0.8781543 , -0.6795782 ], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "    def __init__(self):\n",
    "        env = gym.make('Pendulum-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            done = True\n",
    "        return state, reward, done, info\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0771],\n",
       "         [0.4553]], grad_fn=<MulBackward0>),\n",
       " tensor([[0.9284],\n",
       "         [0.7199]], grad_fn=<NegBackward>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class ModelAction(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_state = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, 128),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = torch.nn.Linear(128, 1)\n",
    "        self.fc_std = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Softplus(),\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        #[b, 3] -> [b, 128]\n",
    "        state = self.fc_state(state)\n",
    "\n",
    "        #[b, 128] -> [b, 1]\n",
    "        mu = self.fc_mu(state)\n",
    "\n",
    "        #[b, 128] -> [b, 1]\n",
    "        std = self.fc_std(state)\n",
    "\n",
    "        #根据mu和std定义b个正态分布\n",
    "        dist = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        #采样b个样本\n",
    "        #这里用的是rsample,表示重采样,其实就是先从一个标准正态分布中采样,然后乘以标准差,加上均值\n",
    "        sample = dist.rsample()\n",
    "\n",
    "        #样本压缩到-1,1之间,求动作\n",
    "        action = torch.tanh(sample)\n",
    "\n",
    "        #求概率对数\n",
    "        log_prob = dist.log_prob(sample)\n",
    "\n",
    "        #这个值描述动作的熵\n",
    "        entropy = log_prob - (1 - action.tanh()**2 + 1e-7).log()\n",
    "        entropy = -entropy\n",
    "\n",
    "        return action * 2, entropy\n",
    "\n",
    "\n",
    "model_action = ModelAction()\n",
    "\n",
    "model_action(torch.randn(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0308],\n",
       "        [-0.1114]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModelValue(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        #[b, 3+1] -> [b, 4]\n",
    "        state = torch.cat([state, action], dim=1)\n",
    "\n",
    "        #[b, 4] -> [b, 1]\n",
    "        return self.sequential(state)\n",
    "\n",
    "\n",
    "model_value1 = ModelValue()\n",
    "model_value2 = ModelValue()\n",
    "\n",
    "model_value_next1 = ModelValue()\n",
    "model_value_next2 = ModelValue()\n",
    "\n",
    "model_value_next1.load_state_dict(model_value1.state_dict())\n",
    "model_value_next2.load_state_dict(model_value2.state_dict())\n",
    "\n",
    "model_value1(torch.randn(2, 3), torch.randn(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.753970205783844"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_action(state):\n",
    "    state = torch.FloatTensor(state).reshape(1, 3)\n",
    "    action, _ = model_action(state)\n",
    "    return action.item()\n",
    "\n",
    "\n",
    "get_action([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,\n",
       " (array([-0.6522397,  0.7580128,  0.9721634], dtype=float32),\n",
       "  1.3092905282974243,\n",
       "  -5.300698704036549,\n",
       "  array([-0.7155343,  0.6985776,  1.7370665], dtype=float32),\n",
       "  False))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#样本池\n",
    "datas = []\n",
    "\n",
    "\n",
    "#向样本池中添加N条数据,删除M条最古老的数据\n",
    "def update_data():\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        next_state, reward, over, _ = env.step([action])\n",
    "\n",
    "        #记录数据样本\n",
    "        datas.append((state, action, reward, next_state, over))\n",
    "\n",
    "        #更新游戏状态,开始下一个动作\n",
    "        state = next_state\n",
    "\n",
    "    #数据上限,超出时从最古老的开始删除\n",
    "    while len(datas) > 100000:\n",
    "        datas.pop(0)\n",
    "\n",
    "\n",
    "update_data()\n",
    "\n",
    "len(datas), datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4384, -0.8988, -5.7731],\n",
       "         [ 0.1364,  0.9906, -6.8175],\n",
       "         [-0.3895,  0.9210, -7.6970],\n",
       "         [-0.9368, -0.3498,  7.4263],\n",
       "         [-0.9165, -0.4001, -7.4470]]),\n",
       " tensor([[-1.4290],\n",
       "         [-0.8067],\n",
       "         [-1.8733],\n",
       "         [-1.8352],\n",
       "         [-1.8813]]),\n",
       " tensor([[ -7.4338],\n",
       "         [ -6.7046],\n",
       "         [ -9.8124],\n",
       "         [-13.2703],\n",
       "         [-13.0022]]),\n",
       " tensor([[-0.7081, -0.7061, -6.6615],\n",
       "         [ 0.4319,  0.9019, -6.1955],\n",
       "         [-0.0357,  0.9994, -7.2873],\n",
       "         [-0.7637, -0.6456,  6.8887],\n",
       "         [-0.9999, -0.0116, -8.0000]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取一批数据样本\n",
    "def get_sample():\n",
    "    #从样本池中采样\n",
    "    samples = random.sample(datas, 64)\n",
    "\n",
    "    #[b, 3]\n",
    "    state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 3)\n",
    "    #[b, 1]\n",
    "    action = torch.FloatTensor([i[1] for i in samples]).reshape(-1, 1)\n",
    "    #[b, 1]\n",
    "    reward = torch.FloatTensor([i[2] for i in samples]).reshape(-1, 1)\n",
    "    #[b, 3]\n",
    "    next_state = torch.FloatTensor([i[3] for i in samples]).reshape(-1, 3)\n",
    "    #[b, 1]\n",
    "    over = torch.LongTensor([i[4] for i in samples]).reshape(-1, 1)\n",
    "\n",
    "    return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "state, action, reward, next_state, over = get_sample()\n",
    "\n",
    "state[:5], action[:5], reward[:5], next_state[:5], over[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1468.662637762065"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "def test(play):\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #记录反馈值的和,这个值越大越好\n",
    "    reward_sum = 0\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        state, reward, over, _ = env.step([action])\n",
    "        reward_sum += reward\n",
    "\n",
    "        #打印动画\n",
    "        if play and random.random() < 0.2:  #跳帧\n",
    "            display.clear_output(wait=True)\n",
    "            show()\n",
    "\n",
    "    return reward_sum\n",
    "\n",
    "\n",
    "test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_update(model, model_next):\n",
    "    for param, param_next in zip(model.parameters(), model_next.parameters()):\n",
    "        #以一个小的比例更新\n",
    "        value = param_next.data * 0.995 + param.data * 0.005\n",
    "        param_next.data.copy_(value)\n",
    "\n",
    "\n",
    "soft_update(torch.nn.Linear(4, 64), torch.nn.Linear(4, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.6052, requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#这也是一个可学习的参数\n",
    "alpha = torch.tensor(math.log(0.01))\n",
    "alpha.requires_grad = True\n",
    "\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target(reward, next_state, over):\n",
    "    #首先使用model_action计算动作和动作的熵\n",
    "    #[b, 4] -> [b, 1],[b, 1]\n",
    "    action, entropy = model_action(next_state)\n",
    "\n",
    "    #评估next_state的价值\n",
    "    #[b, 4],[b, 1] -> [b, 1]\n",
    "    target1 = model_value_next1(next_state, action)\n",
    "    target2 = model_value_next2(next_state, action)\n",
    "\n",
    "    #取价值小的,这是出于稳定性考虑\n",
    "    #[b, 1]\n",
    "    target = torch.min(target1, target2)\n",
    "\n",
    "    #exp和log互为反操作,这里是把alpha还原了\n",
    "    #这里的操作是在target上加上了动作的熵,alpha作为权重系数\n",
    "    #[b, 1] - [b, 1] -> [b, 1]\n",
    "    target += alpha.exp() * entropy\n",
    "\n",
    "    #[b, 1]\n",
    "    target *= 0.99\n",
    "    target *= (1 - over)\n",
    "    target += reward\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "get_target(reward, next_state, over).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2643, grad_fn=<MeanBackward0>),\n",
       " tensor([[ 0.7915],\n",
       "         [-0.2055],\n",
       "         [ 0.1777],\n",
       "         [ 0.4656],\n",
       "         [-0.4531],\n",
       "         [ 0.4831],\n",
       "         [ 0.7837],\n",
       "         [ 0.5182],\n",
       "         [ 0.5807],\n",
       "         [-0.3043],\n",
       "         [-0.0485],\n",
       "         [ 0.5566],\n",
       "         [-0.3825],\n",
       "         [ 1.0466],\n",
       "         [-0.5135],\n",
       "         [-0.1574],\n",
       "         [ 0.2675],\n",
       "         [ 0.1302],\n",
       "         [ 0.8504],\n",
       "         [ 0.1966],\n",
       "         [ 0.0937],\n",
       "         [-0.4416],\n",
       "         [ 1.2394],\n",
       "         [ 1.6066],\n",
       "         [ 1.3113],\n",
       "         [ 1.0832],\n",
       "         [ 0.0406],\n",
       "         [ 1.2671],\n",
       "         [-0.6935],\n",
       "         [ 1.6894],\n",
       "         [ 0.3122],\n",
       "         [ 0.0357],\n",
       "         [ 0.4353],\n",
       "         [-0.2470],\n",
       "         [ 0.3698],\n",
       "         [ 0.3805],\n",
       "         [ 1.7253],\n",
       "         [-0.2183],\n",
       "         [-0.3892],\n",
       "         [-0.4130],\n",
       "         [-0.0712],\n",
       "         [ 1.6824],\n",
       "         [-0.2828],\n",
       "         [ 1.5402],\n",
       "         [ 0.4781],\n",
       "         [-0.5146],\n",
       "         [ 0.9263],\n",
       "         [ 0.9249],\n",
       "         [ 0.3295],\n",
       "         [ 0.5386],\n",
       "         [ 0.3938],\n",
       "         [-0.1447],\n",
       "         [ 0.5005],\n",
       "         [ 2.2619],\n",
       "         [-0.0311],\n",
       "         [ 0.7727],\n",
       "         [-0.1829],\n",
       "         [ 1.1701],\n",
       "         [-0.0592],\n",
       "         [-0.2915],\n",
       "         [ 0.3997],\n",
       "         [-0.6187],\n",
       "         [-0.1993],\n",
       "         [ 0.0291]], grad_fn=<NegBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss_action(state):\n",
    "    #计算action和熵\n",
    "    #[b, 3] -> [b, 1],[b, 1]\n",
    "    action, entropy = model_action(state)\n",
    "\n",
    "    #使用两个value网络评估action的价值\n",
    "    #[b, 3],[b, 1] -> [b, 1]\n",
    "    value1 = model_value1(state, action)\n",
    "    value2 = model_value2(state, action)\n",
    "\n",
    "    #取价值小的,出于稳定性考虑\n",
    "    #[b, 1]\n",
    "    value = torch.min(value1, value2)\n",
    "\n",
    "    #alpha还原后乘以熵,这个值期望的是越大越好,但是这里是计算loss,所以符号取反\n",
    "    #[1] - [b, 1] -> [b, 1]\n",
    "    loss_action = -alpha.exp() * entropy\n",
    "\n",
    "    #减去value,所以value越大越好,这样loss就会越小\n",
    "    loss_action -= value\n",
    "\n",
    "    return loss_action.mean(), entropy\n",
    "\n",
    "\n",
    "get_loss_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OHoSU6uI-xIt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 -1604.85017631161\n",
      "2400 -1071.0996546207134\n",
      "4400 -339.77068327511023\n",
      "6400 -351.9092491293369\n",
      "8400 -152.16755011939136\n",
      "10400 -177.98539578645585\n",
      "12400 -337.44063662825766\n",
      "14400 -110.50963497765144\n",
      "16400 -189.16868175068169\n",
      "18400 -148.17073024789696\n",
      "20400 -176.88575617779603\n",
      "22400 -182.79036443588683\n",
      "24400 -181.06796321265892\n",
      "26400 -188.9760013655387\n",
      "28400 -158.87839279185877\n",
      "30400 -124.40343072275884\n",
      "32400 -152.06886636759577\n",
      "34400 -165.40013577610188\n",
      "36400 -110.36330266287152\n",
      "38400 -147.15575107946006\n",
      "40400 -225.78040577861393\n",
      "42400 -149.32928740809842\n",
      "44400 -288.7929535146113\n",
      "46400 -569.2659909146579\n",
      "48400 -170.76593353762905\n",
      "50400 -158.67457005415264\n",
      "52400 -159.36836374629578\n",
      "54400 -85.92456050253662\n",
      "56400 -161.2748416903053\n",
      "58400 -169.7411981584319\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    optimizer_action = torch.optim.Adam(model_action.parameters(), lr=3e-4)\n",
    "    optimizer_value1 = torch.optim.Adam(model_value1.parameters(), lr=3e-3)\n",
    "    optimizer_value2 = torch.optim.Adam(model_value2.parameters(), lr=3e-3)\n",
    "\n",
    "    #alpha也是要更新的参数,所以这里要定义优化器\n",
    "    optimizer_alpha = torch.optim.Adam([alpha], lr=3e-4)\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(300):\n",
    "        #更新N条数据\n",
    "        update_data()\n",
    "\n",
    "        #每次更新过数据后,学习N次\n",
    "        for i in range(200):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = get_sample()\n",
    "\n",
    "            #对reward偏移,为了便于训练\n",
    "            reward = (reward + 8) / 8\n",
    "\n",
    "            #计算target,这个target里已经考虑了动作的熵\n",
    "            #[b, 1]\n",
    "            target = get_target(reward, next_state, over)\n",
    "            target = target.detach()\n",
    "\n",
    "            #计算两个value\n",
    "            value1 = model_value1(state, action)\n",
    "            value2 = model_value2(state, action)\n",
    "\n",
    "            #计算两个loss,两个value的目标都是要贴近target\n",
    "            loss_value1 = loss_fn(value1, target)\n",
    "            loss_value2 = loss_fn(value2, target)\n",
    "\n",
    "            #更新参数\n",
    "            optimizer_value1.zero_grad()\n",
    "            loss_value1.backward()\n",
    "            optimizer_value1.step()\n",
    "\n",
    "            optimizer_value2.zero_grad()\n",
    "            loss_value2.backward()\n",
    "            optimizer_value2.step()\n",
    "\n",
    "            #使用model_value计算model_action的loss\n",
    "            loss_action, entropy = get_loss_action(state)\n",
    "            optimizer_action.zero_grad()\n",
    "            loss_action.backward()\n",
    "            optimizer_action.step()\n",
    "\n",
    "            #熵乘以alpha就是alpha的loss\n",
    "            #[b, 1] -> [1]\n",
    "            loss_alpha = (entropy + 1).detach() * alpha.exp()\n",
    "            loss_alpha = loss_alpha.mean()\n",
    "\n",
    "            #更新alpha值\n",
    "            optimizer_alpha.zero_grad()\n",
    "            loss_alpha.backward()\n",
    "            optimizer_alpha.step()\n",
    "\n",
    "            #增量更新next模型\n",
    "            soft_update(model_value1, model_value_next1)\n",
    "            soft_update(model_value2, model_value_next2)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_result = sum([test(play=False) for _ in range(10)]) / 10\n",
    "            print(len(datas), test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-127.48646701560392"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
