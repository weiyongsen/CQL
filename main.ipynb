{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 22:49:50,990\tINFO worker.py:1351 -- Calling ray.init() again after it has already been called.\n",
      "2025-03-17 22:49:50,994\tWARNING deprecation.py:47 -- DeprecationWarning: `config['multiagent']['replay_mode']` has been deprecated. config['replay_buffer_config']['replay_mode'] This will raise an error in the future!\n",
      "2025-03-17 22:49:52,365\tWARNING json_reader.py:166 -- Treating input directory as glob patterns: ['d:\\\\Desktop\\\\CQL\\\\path\\\\to\\\\offline_data\\\\*.json', 'd:\\\\Desktop\\\\CQL\\\\path\\\\to\\\\offline_data\\\\*.zip']\n",
      "2025-03-17 22:49:52,367\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "2025-03-17 22:49:52,392\tWARNING algorithm.py:2178 -- Worker crashed during training or evaluation! To try to continue without failed worker(s), set `ignore_worker_failures=True`. To try to recover the failed worker(s), set `recreate_failed_workers=True`.\n"
     ]
    },
    {
     "ename": "RayTaskError(ValueError)",
     "evalue": "\u001b[36mray::RolloutWorker.sample()\u001b[39m (pid=58604, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000016308F04B20>)\n  File \"python\\ray\\_raylet.pyx\", line 662, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 666, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 613, in ray._raylet.execute_task.function_executor\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n    return method(self, *_args, **_kwargs)\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 806, in sample\n    batches = [self.input_reader.next()]\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\offline\\shuffled_input.py\", line 34, in next\n    return self.child.next()\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\offline\\json_reader.py\", line 203, in next\n    raise ValueError(\nValueError: Failed to read valid experience batch from file: <_io.TextIOWrapper name='d:\\\\Desktop\\\\CQL\\\\path\\\\to\\\\offline_data\\\\offline_data.json' mode='r' encoding='UTF-8'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(ValueError)\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 离线训练循环\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pretty_print(result))\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:347\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warmup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n\u001b[0;32m    346\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 347\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep() needs to return a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:661\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    653\u001b[0m     (\n\u001b[0;32m    654\u001b[0m         results,\n\u001b[0;32m    655\u001b[0m         train_iter_ctx,\n\u001b[0;32m    656\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[0;32m    657\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 661\u001b[0m     results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_parallel_to_training\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2378\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2376\u001b[0m         \u001b[38;5;66;03m# In case of any failures, try to ignore/recover the failed workers.\u001b[39;00m\n\u001b[0;32m   2377\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2378\u001b[0m             num_recreated \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_recover_from_step_attempt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m                \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m                \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m                \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore_worker_failures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrecreate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecreate_failed_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2383\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2384\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_recreated_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_recreated\n\u001b[0;32m   2386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, train_iter_ctx\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2185\u001b[0m, in \u001b[0;36mAlgorithm.try_recover_from_step_attempt\u001b[1;34m(self, error, worker_set, ignore, recreate)\u001b[0m\n\u001b[0;32m   2176\u001b[0m     \u001b[38;5;66;03m# Error out.\u001b[39;00m\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2178\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   2179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorker crashed during training or evaluation! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2180\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo try to continue without failed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2183\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`recreate_failed_workers=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2184\u001b[0m         )\n\u001b[1;32m-> 2185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m   2186\u001b[0m \u001b[38;5;66;03m# Any other exception.\u001b[39;00m\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# Allow logs messages to propagate.\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:2373\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[0;32m   2372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_disable_execution_plan_api\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m-> 2373\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2375\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\algorithms\\cql\\cql.py:178\u001b[0m, in \u001b[0;36mCQL.training_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@override\u001b[39m(SAC)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultDict:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# Collect SampleBatches from sample workers.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[SAMPLE_TIMER]:\n\u001b[1;32m--> 178\u001b[0m         train_batch \u001b[38;5;241m=\u001b[39m \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mas_multi_agent()\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39magent_steps()\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py:100\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[1;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001b[0m\n\u001b[0;32m     97\u001b[0m     sample_batches \u001b[38;5;241m=\u001b[39m [worker_set\u001b[38;5;241m.\u001b[39mlocal_worker()\u001b[38;5;241m.\u001b[39msample()]\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     sample_batches \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mworker\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Update our counters for the stopping criterion of the while loop.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m sample_batches:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\_private\\worker.py:2275\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2273\u001b[0m     worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[1;32m-> 2275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[0;32m   2276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[1;31mRayTaskError(ValueError)\u001b[0m: \u001b[36mray::RolloutWorker.sample()\u001b[39m (pid=58604, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000016308F04B20>)\n  File \"python\\ray\\_raylet.pyx\", line 662, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 666, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 613, in ray._raylet.execute_task.function_executor\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n    return method(self, *_args, **_kwargs)\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 806, in sample\n    batches = [self.input_reader.next()]\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\offline\\shuffled_input.py\", line 34, in next\n    return self.child.next()\n  File \"d:\\miniconda3\\envs\\torch191\\lib\\site-packages\\ray\\rllib\\offline\\json_reader.py\", line 203, in next\n    raise ValueError(\nValueError: Failed to read valid experience batch from file: <_io.TextIOWrapper name='d:\\\\Desktop\\\\CQL\\\\path\\\\to\\\\offline_data\\\\offline_data.json' mode='r' encoding='UTF-8'>"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib.algorithms.cql as cql\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# 复制默认配置，并指定离线数据路径\n",
    "config = cql.DEFAULT_CONFIG.copy()\n",
    "config[\"num_workers\"] = 1\n",
    "config[\"framework\"] = \"torch\"\n",
    "# 指定离线数据输入路径，RLlib 会自动加载该目录下的 JSON Lines 文件\n",
    "config[\"input\"] = \"tmp/pendulum-out\"\n",
    "\n",
    "# 注意：离线训练时，算法不会与环境交互采集数据\n",
    "algo = cql.CQL(config=config, env=\"Pendulum-v1\")\n",
    "\n",
    "# 离线训练循环\n",
    "for i in range(100):\n",
    "    result = algo.train()\n",
    "    print(pretty_print(result))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        checkpoint = algo.save(\"save_model\")\n",
    "        print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ray\n",
    "import ray.rllib.algorithms.cql as cql\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "config = cql.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 0\n",
    "config[\"num_workers\"] = 1\n",
    "config[\"framework\"] = \"torch\"\n",
    "algo = cql.CQL(config=config, env=\"Pendulum-v1\")\n",
    "\n",
    "# 加载之前保存的checkpoint（请将此路径替换为实际的checkpoint路径）\n",
    "checkpoint_path = \"save_model/your_checkpoint_directory_or_file\"  \n",
    "algo.restore(checkpoint_path)\n",
    "\n",
    "# 使用加载的模型在环境中进行测试\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = algo.compute_action(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "ray.shutdown()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch191",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
