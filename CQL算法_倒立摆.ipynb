{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95878977, 0.28411648, 0.01650543], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "    def __init__(self):\n",
    "        env = gym.make('Pendulum-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            done = True\n",
    "        return state, reward, done, info\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGiCAYAAABd6zmYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkCklEQVR4nO3df3DU9YH/8ddns9mF/NgNCWRDJBGuUmmOH62gsDpXbUlJbVprxRvPYzzOMnbkgiPScU7uFEfvZuLY+56tV8Wb6Zw61yp33IlWKnIxYLA1/DBCRcC0VtpEYBMgl90QyObHvr9/WPZcDJofn2TfSZ6PmZ0xn89733nvR9gn2f3sJ44xxggAAAt50r0AAAAuhkgBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKyVtkg98cQTmjlzpiZNmqTFixdr79696VoKAMBSaYnUf/zHf2jdunV68MEH9fbbb2vBggWqqKhQa2trOpYDALCUk44LzC5evFhXXnmlfvzjH0uSEomESkpKdNddd+m+++4b7eUAACzlHe1v2N3drYaGBq1fvz65zePxqLy8XPX19f3eJx6PKx6PJ79OJBJqa2tTQUGBHMcZ8TUDANxljFFHR4eKi4vl8Vz8Rb1Rj9SpU6fU19enUCiUsj0UCum9997r9z7V1dV66KGHRmN5AIBR1NzcrBkzZlx0/6hHaijWr1+vdevWJb+ORqMqLS1Vc3OzAoFAGlcGABiKWCymkpIS5ebmfuq4UY/U1KlTlZGRoZaWlpTtLS0tKioq6vc+fr9ffr//E9sDgQCRAoAx7LPeshn1s/t8Pp8WLlyo2tra5LZEIqHa2lqFw+HRXg4AwGJpeblv3bp1WrlypRYtWqSrrrpKP/zhD9XZ2anbb789HcsBAFgqLZG65ZZbdPLkSW3YsEGRSERf/OIX9eqrr37iZAoAwMSWls9JDVcsFlMwGFQ0GuU9KQAYgwb6PM61+wAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYa9CR2rVrl771rW+puLhYjuPoxRdfTNlvjNGGDRs0ffp0TZ48WeXl5frtb3+bMqatrU0rVqxQIBBQXl6eVq1apTNnzgzrgQAAxp9BR6qzs1MLFizQE0880e/+Rx99VI8//rieeuop7dmzR9nZ2aqoqFBXV1dyzIoVK3To0CHV1NRo69at2rVrl773ve8N/VEAAMYnMwySzJYtW5JfJxIJU1RUZH7wgx8kt7W3txu/32+ef/55Y4wxhw8fNpLMvn37kmO2bdtmHMcxx44dG9D3jUajRpKJRqPDWT4AIE0G+jzu6ntSR48eVSQSUXl5eXJbMBjU4sWLVV9fL0mqr69XXl6eFi1alBxTXl4uj8ejPXv29DtvPB5XLBZLuQEAxj9XIxWJRCRJoVAoZXsoFErui0QiKiwsTNnv9XqVn5+fHHOh6upqBYPB5K2kpMTNZQMALDUmzu5bv369otFo8tbc3JzuJQEARoGrkSoqKpIktbS0pGxvaWlJ7isqKlJra2vK/t7eXrW1tSXHXMjv9ysQCKTcAADjn6uRmjVrloqKilRbW5vcFovFtGfPHoXDYUlSOBxWe3u7GhoakmN27NihRCKhxYsXu7kcAMAY5x3sHc6cOaP3338/+fXRo0d14MAB5efnq7S0VGvXrtU//uM/avbs2Zo1a5YeeOABFRcX68Ybb5QkfeELX9DXv/513XHHHXrqqafU09OjNWvW6C/+4i9UXFzs2gMDAIwDgz1tcOfOnUbSJ24rV640xnx0GvoDDzxgQqGQ8fv9ZunSpaaxsTFljtOnT5tbb73V5OTkmEAgYG6//XbT0dHh+qmLAAA7DfR53DHGmDQ2ckhisZiCwaCi0SjvTwHAGDTQ5/ExcXYfAGBiIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCw1qB/6SEwEZneXnWfOqXoW28p9s476jl5UnIc+adPV+6CBQpecYUyp0yRk5GR7qUC4wqRAj5Dd1ubTr/2mlpfflm90WjKvrPvv6//feMNZU6dqul//ufKu/pqZQaDaVopMP4QKeBTdJ88qePPP6+211+X6e296LieU6f04dNPq+vYMU2/5RZ5c3NHcZXA+MV7UsBF9HV26thPf/qZgTov0dWlk9u26cR//qcSPT2jsEJg/CNSwEWcfPVVte3cOaBAnWd6enTyF79Q265dI7gyYOIgUkA/etrbdXL79iHd1/T26vi//7uiDQ0yxri8MmBiIVJAP1p//nN1t7YO+f49bW1qe/119XV2urgqYOIhUkA/+rq6pERiWHO01dWp+9Qpl1YETExEChhBve3tvOQHDAORAkZQ++7d6V4CMKYRKWAEte3aNaizAwGkIlJAPxzHcWUe09enrqYmV+YCJiIiBfQj/ytfUWZ+/rDnSZw7p8gLL7iwImBiIlJAPyZfeqk8kye7Mlff2bPqO3fOlbmAiYZIAf3wZGYqb/FiV+bqPHJE0YYGV+YCJhoiBVxE/p/9mSvz9J09y6nowBARKeAiMgsKXJur68QJme5u1+YDJgoiBVxExuTJmrpsmStzte3cqZ72dlfmAiYSIgVchOPzKXf+fFfm6jtzRr2xGC/5AYNEpICLcBxHvlBI/unTXZmPU9GBwSNSwKfImjlTWbNnuzJX5+HDEj9JAYNCpIBP4fh8mnTJJXK83mHPlejt1bkPP3RhVcDEQaSAT+E4jqZcc40ysrOHPVfi7Fm1/+pXLqwKmDiIFPAZJs2YIY/PN+x5TF+fupqblejpcWFVwMRApIDP4Hg8yr78clfmOvvBBzr7wQeuzAVMBEQKGICim292ZZ748eOKHzvGqejAABEpYAC8gYAr70tJ0tn335fhJT9gQIgUMADeYFDTKitdmat161b1dnS4Mhcw3hEpYAAcr1f+wkLX5us7e9a1uYDxjEgBA+A4jrLLylz7YG97fb0r8wDjHZECBsgfCsk3bZorc51+7TVX5gHGOyIFDJAnM9OVz0tJUqKnR/GWFlfmAsYzIgUMQvFf/qUycnKGPU/P6dNqefHF4S8IGOeIFDAIvlBITkaGK3Mlzp3j6hPAZyBSwCC5dSp6PBJRz+nTrswFjFdEChikKVdf7co8Zw4f1tnf/Y6rTwCfgkgBg+A4jjKyszV51ixX5ou3tkqJhCtzAeMRkQIGyRsMKnjVVa7M1fLCC+o7d86VuYDxiEgBg+RkZGjSJZfIM2nSsOfqjcXU19npwqqA8YlIAYPkOI5y5szRpJKS4U9mjFq2bBn+PMA4RaSAIfBNm6bMYNCVuToOHeLkCeAiiBQwBE5GxkcnT3iG/1fIdHdzKjpwEUQKGKLCG26Qx+8f9jw9bW1q373bhRUB4w+RAobIm5Mjb27usOdJxOOKnzghw6nowCcQKWCoPB5Nv+UWV6bqOHxYXceOuTIXMJ4QKWAYJl96qSvznPvd79Td2soJFMAFiBQwRI7jyFdYqMDCha7MF29pkYgUkIJIAcPgzclR1p/8iStzte3aJdPb68pcwHhBpIBhcLxeZWRluTJXZ2OjEt3drswFjBeDilR1dbWuvPJK5ebmqrCwUDfeeKMaGxtTxnR1damqqkoFBQXKycnR8uXL1XLBbyBtampSZWWlsrKyVFhYqHvvvVe9/AsSY1T+tdcq63OfG/5EiQSnogMXGFSk6urqVFVVpd27d6umpkY9PT1atmyZOj927bF77rlHL7/8sjZv3qy6ujodP35cN910U3J/X1+fKisr1d3drTfffFPPPvusnnnmGW3YsMG9RwWMIt/UqcrIzh7+RMbo5KuvDn8eYBxxzDBOJzp58qQKCwtVV1enL3/5y4pGo5o2bZqee+453XzzzZKk9957T1/4whdUX1+vJUuWaNu2bfrmN7+p48ePKxQKSZKeeuop/e3f/q1Onjwpn8/3md83FospGAwqGo0qEAgMdfmAa0699pr+8MQTUl/fsOaZPHOmZv/DP7h2ySXAVgN9Hh/We1LRaFSSlJ+fL0lqaGhQT0+PysvLk2PmzJmj0tJS1dfXS5Lq6+s1b968ZKAkqaKiQrFYTIcOHer3+8TjccVisZQbYJMpV1/tyq+V72lrU+eRIy6sCBgfhhypRCKhtWvX6pprrtHcuXMlSZFIRD6fT3l5eSljQ6GQIpFIcszHA3V+//l9/amurlYwGEzeSty4+jTgIo/Pp+zPf37Y8/TGYjrT2MjVJ4A/GnKkqqqq9O6772rTpk1urqdf69evVzQaTd6am5tH/HsCg5KRoYKlS12ZKn7smHp5tQCQNMRIrVmzRlu3btXOnTs1Y8aM5PaioiJ1d3ervb09ZXxLS4uKioqSYy482+/81+fHXMjv9ysQCKTcANv4L/Lnd7Dad+/mEknAHw0qUsYYrVmzRlu2bNGOHTs0a9aslP0LFy5UZmamamtrk9saGxvV1NSkcDgsSQqHwzp48KBaW1uTY2pqahQIBFRWVjacxwKkjeM48hUUKMuFl/wkqef0aS6RBGiQkaqqqtJPf/pTPffcc8rNzVUkElEkEtG5c+ckScFgUKtWrdK6deu0c+dONTQ06Pbbb1c4HNaSJUskScuWLVNZWZluu+02/frXv9b27dt1//33q6qqSn4Xfu0BkC6+wkIF5s93Za5jzz7L1ScASd7BDN64caMk6brrrkvZ/vTTT+uv//qvJUmPPfaYPB6Pli9frng8roqKCj355JPJsRkZGdq6datWr16tcDis7OxsrVy5Ug8//PDwHgmQZo7HI//06fJMnqzEH//hNlQ90agS3d3yZGa6tDpgbBrW56TShc9JwVa9HR36zf3369zRo8Oax/F6Nfuhh5Q7b55LKwPsMiqfkwKQKiMnR14XPohrenvV8tJLvC+FCY9IAS5yHEdFy5dLnuH/1eqNRtV39qwLqwLGLiIFuCxr1izJcYY9T9eHHyq6d68LKwLGLiIFuMzx+Vy59l5fZ6e6W1q4+gQmNCIFuMzj9+uSP57tOlxdx4/zkh8mNCIFuMxxHHldOus09vbb6mlr4wQKTFhEChgB2Zddprw/XmVlOHpjMcU/dnUWYKIhUsAI8AYC8l1wtf+hOrV9u8RPUpigiBQwQnLnzXPlZb+OgwclTp7ABEWkgBGSO2+eax/sjb79tgsrAsYeIgWMkIxJk1z5RYimu/ujl/yACYhIASPIrV+EmOjuVt8wL1oLjEVEChhBk0tLXbn6RPzECZ19/30XVgSMLUQKGEGOz6fcL35x2PN0t7bq7O9/z+elMOEQKWAEefx+FXzlK67M1dXUpERXlytzAWMFkQJGkOM4yszPd+Usv1Pbt6v71CkXVgWMHUQKGGHZn/uccufOdWWu3liMl/wwoRApYIR5srKUWVDgygkU0bfecmFFwNhBpIAR5jiO8q+7zpWX/E6/9prU1+fCqoCxgUgBo2Byaak8fv+w5zG9veo6ftyFFQFjA5ECRoHH51NmXt6w5+k7e1YtL700/AUBYwSRAkZJyR13DH8SY9QbiykRjw9/LmAMIFLAKMmcOtWVeTrfe++jK6MDEwCRAkaJNydH0775zWHP0xuNKh6JyPDrOzABeNO9AGCicDIzlfW5z33muGOdndrf1qaOnh5NmzRJ4WnTlJ2ZmTKm7Y03lP/lL7v2a+oBWxEpYJQ4jqPJJSXyX3KJ4seOfWK/MUZHz5zRg/v36/dnzqirr0+BzEzNnTJF/3Tllcr0/N8LH51HjujsBx8od8ECOS58/gqwFS/3AaNo0qWXavKll/a774MzZ3THr36lI9GozvX1yUiK9vToV62tunvPHp2+4Lp9TU89NQorBtKLSAGjKMPvv+jnpX546JCiPT397tt76pRqLvh8lLnIWGA8IVLAKJv6ta8pIzs73csAxgQiBYyynD/9U1euPgFMBEQKSIPAFVd8YltlSYkyL3ISxMycHM3Pzx/pZQHWIVJAGhTecIMcny9lW0VxsR780pc0KSMj+Rczw3FU4Pfr/115pcouuKxSaPny0VkskEacgg6MMsdxNPnSSzXr+9/XH378Y/V1dCS3VxQXa0ZWlrZ++KFOd3VpZk6Obpk1SwUXvDzonz5dU8JhTj/HuEekgDRwHEfBK67QtOuvV8t//7fMH3/9huM4mjtliuZOmXLR+3qnTFHxbbfxQV5MCLzcB6SJx+9X6DvfUf5XvyrHO7B/L2bk5Gj6Lbco76qr5GRkjPAKgfTjJykgjTKysjTju99VZn6+2nbuVHdra7/jnIwMTSop+Shq113Hy3yYMIgUkEaO48ibna3pN9+swPz5+t8339SZQ4cUj0SUiMeVkZOjSTNmKLhokYKLFmlyaSmBwoRCpAALePx+5cydq+zPf159587J9PbKJBJyMjLkycyUJytLngG+JAiMJ/ypByzhOI6cT7lsEjARceIEAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtQYVqY0bN2r+/PkKBAIKBAIKh8Patm1bcn9XV5eqqqpUUFCgnJwcLV++XC0tLSlzNDU1qbKyUllZWSosLNS9996r3t5edx4NAGBcGVSkZsyYoUceeUQNDQ1666239NWvflXf/va3dejQIUnSPffco5dfflmbN29WXV2djh8/rptuuil5/76+PlVWVqq7u1tvvvmmnn32WT3zzDPasGGDu48KADA+mGGaMmWK+clPfmLa29tNZmam2bx5c3LfkSNHjCRTX19vjDHmlVdeMR6Px0QikeSYjRs3mkAgYOLx+IC/ZzQaNZJMNBod7vIBAGkw0OfxIb8n1dfXp02bNqmzs1PhcFgNDQ3q6elReXl5csycOXNUWlqq+vp6SVJ9fb3mzZunUCiUHFNRUaFYLJb8aaw/8XhcsVgs5QYAGP8GHamDBw8qJydHfr9fd955p7Zs2aKysjJFIhH5fD7l5eWljA+FQopEIpKkSCSSEqjz+8/vu5jq6moFg8HkraSkZLDLBgCMQYOO1OWXX64DBw5oz549Wr16tVauXKnDhw+PxNqS1q9fr2g0mrw1NzeP6PcDANjBO9g7+Hw+XXbZZZKkhQsXat++ffrRj36kW265Rd3d3Wpvb0/5aaqlpUVFRUWSpKKiIu3duzdlvvNn/50f0x+/3y+/3z/YpQIAxrhhf04qkUgoHo9r4cKFyszMVG1tbXJfY2OjmpqaFA6HJUnhcFgHDx5Ua2trckxNTY0CgYDKysqGuxQAwDgzqJ+k1q9fr+uvv16lpaXq6OjQc889p9dff13bt29XMBjUqlWrtG7dOuXn5ysQCOiuu+5SOBzWkiVLJEnLli1TWVmZbrvtNj366KOKRCK6//77VVVVxU9KAIBPGFSkWltb9Vd/9Vc6ceKEgsGg5s+fr+3bt+trX/uaJOmxxx6Tx+PR8uXLFY/HVVFRoSeffDJ5/4yMDG3dulWrV69WOBxWdna2Vq5cqYcfftjdRwUAGBccY4xJ9yIGKxaLKRgMKhqNKhAIpHs5AIBBGujzONfuAwBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGCtYUXqkUcekeM4Wrt2bXJbV1eXqqqqVFBQoJycHC1fvlwtLS0p92tqalJlZaWysrJUWFioe++9V729vcNZCgBgHBpypPbt26d//dd/1fz581O233PPPXr55Ze1efNm1dXV6fjx47rpppuS+/v6+lRZWanu7m69+eabevbZZ/XMM89ow4YNQ38UAIDxyQxBR0eHmT17tqmpqTHXXnutufvuu40xxrS3t5vMzEyzefPm5NgjR44YSaa+vt4YY8wrr7xiPB6PiUQiyTEbN240gUDAxOPxAX3/aDRqJJloNDqU5QMA0mygz+ND+kmqqqpKlZWVKi8vT9ne0NCgnp6elO1z5sxRaWmp6uvrJUn19fWaN2+eQqFQckxFRYVisZgOHTrU7/eLx+OKxWIpNwDA+Ocd7B02bdqkt99+W/v27fvEvkgkIp/Pp7y8vJTtoVBIkUgkOebjgTq///y+/lRXV+uhhx4a7FIBAGPcoH6Sam5u1t13362f/exnmjRp0kit6RPWr1+vaDSavDU3N4/a9wYApM+gItXQ0KDW1lZdccUV8nq98nq9qqur0+OPPy6v16tQKKTu7m61t7en3K+lpUVFRUWSpKKiok+c7Xf+6/NjLuT3+xUIBFJuAIDxb1CRWrp0qQ4ePKgDBw4kb4sWLdKKFSuS/52Zmana2trkfRobG9XU1KRwOCxJCofDOnjwoFpbW5NjampqFAgEVFZW5tLDAgCMB4N6Tyo3N1dz585N2Zadna2CgoLk9lWrVmndunXKz89XIBDQXXfdpXA4rCVLlkiSli1bprKyMt1222169NFHFYlEdP/996uqqkp+v9+lhwUAGA8GfeLEZ3nsscfk8Xi0fPlyxeNxVVRU6Mknn0zuz8jI0NatW7V69WqFw2FlZ2dr5cqVevjhh91eCgBgjHOMMSbdixisWCymYDCoaDTK+1MAMAYN9Hmca/cBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKzlTfcChsIYI0mKxWJpXgkAYCjOP3+ffz6/mDEZqdOnT0uSSkpK0rwSAMBwdHR0KBgMXnT/mIxUfn6+JKmpqelTH9xEF4vFVFJSoubmZgUCgXQvx1ocp4HhOA0Mx2lgjDHq6OhQcXHxp44bk5HyeD56Ky0YDPKHYAACgQDHaQA4TgPDcRoYjtNnG8gPGZw4AQCwFpECAFhrTEbK7/frwQcflN/vT/dSrMZxGhiO08BwnAaG4+Qux3zW+X8AAKTJmPxJCgAwMRApAIC1iBQAwFpECgBgrTEZqSeeeEIzZ87UpEmTtHjxYu3duzfdSxpVu3bt0re+9S0VFxfLcRy9+OKLKfuNMdqwYYOmT5+uyZMnq7y8XL/97W9TxrS1tWnFihUKBALKy8vTqlWrdObMmVF8FCOrurpaV155pXJzc1VYWKgbb7xRjY2NKWO6urpUVVWlgoIC5eTkaPny5WppaUkZ09TUpMrKSmVlZamwsFD33nuvent7R/OhjKiNGzdq/vz5yQ+ehsNhbdu2LbmfY9S/Rx55RI7jaO3atcltHKsRYsaYTZs2GZ/PZ/7t3/7NHDp0yNxxxx0mLy/PtLS0pHtpo+aVV14xf//3f29eeOEFI8ls2bIlZf8jjzxigsGgefHFF82vf/1rc8MNN5hZs2aZc+fOJcd8/etfNwsWLDC7d+82b7zxhrnsssvMrbfeOsqPZORUVFSYp59+2rz77rvmwIED5hvf+IYpLS01Z86cSY658847TUlJiamtrTVvvfWWWbJkibn66quT+3t7e83cuXNNeXm52b9/v3nllVfM1KlTzfr169PxkEbEz3/+c/OLX/zC/OY3vzGNjY3m7/7u70xmZqZ59913jTEco/7s3bvXzJw508yfP9/cfffdye0cq5Ex5iJ11VVXmaqqquTXfX19pri42FRXV6dxVelzYaQSiYQpKioyP/jBD5Lb2tvbjd/vN88//7wxxpjDhw8bSWbfvn3JMdu2bTOO45hjx46N2tpHU2trq5Fk6urqjDEfHZPMzEyzefPm5JgjR44YSaa+vt4Y89E/Bjwej4lEIskxGzduNIFAwMTj8dF9AKNoypQp5ic/+QnHqB8dHR1m9uzZpqamxlx77bXJSHGsRs6Yermvu7tbDQ0NKi8vT27zeDwqLy9XfX19Gldmj6NHjyoSiaQco2AwqMWLFyePUX19vfLy8rRo0aLkmPLycnk8Hu3Zs2fU1zwaotGopP+7OHFDQ4N6enpSjtOcOXNUWlqacpzmzZunUCiUHFNRUaFYLKZDhw6N4upHR19fnzZt2qTOzk6Fw2GOUT+qqqpUWVmZckwk/jyNpDF1gdlTp06pr68v5X+yJIVCIb333ntpWpVdIpGIJPV7jM7vi0QiKiwsTNnv9XqVn5+fHDOeJBIJrV27Vtdcc43mzp0r6aNj4PP5lJeXlzL2wuPU33E8v2+8OHjwoMLhsLq6upSTk6MtW7aorKxMBw4c4Bh9zKZNm/T2229r3759n9jHn6eRM6YiBQxFVVWV3n33Xf3yl79M91KsdPnll+vAgQOKRqP6r//6L61cuVJ1dXXpXpZVmpubdffdd6umpkaTJk1K93ImlDH1ct/UqVOVkZHxiTNmWlpaVFRUlKZV2eX8cfi0Y1RUVKTW1taU/b29vWpraxt3x3HNmjXaunWrdu7cqRkzZiS3FxUVqbu7W+3t7SnjLzxO/R3H8/vGC5/Pp8suu0wLFy5UdXW1FixYoB/96Ecco49paGhQa2urrrjiCnm9Xnm9XtXV1enxxx+X1+tVKBTiWI2QMRUpn8+nhQsXqra2NrktkUiotrZW4XA4jSuzx6xZs1RUVJRyjGKxmPbs2ZM8RuFwWO3t7WpoaEiO2bFjhxKJhBYvXjzqax4JxhitWbNGW7Zs0Y4dOzRr1qyU/QsXLlRmZmbKcWpsbFRTU1PKcTp48GBK0GtqahQIBFRWVjY6DyQNEomE4vE4x+hjli5dqoMHD+rAgQPJ26JFi7RixYrkf3OsRki6z9wYrE2bNhm/32+eeeYZc/jwYfO9733P5OXlpZwxM951dHSY/fv3m/379xtJ5p//+Z/N/v37zR/+8AdjzEenoOfl5ZmXXnrJvPPOO+bb3/52v6egf+lLXzJ79uwxv/zlL83s2bPH1Snoq1evNsFg0Lz++uvmxIkTydvZs2eTY+68805TWlpqduzYYd566y0TDodNOBxO7j9/yvCyZcvMgQMHzKuvvmqmTZs2rk4Zvu+++0xdXZ05evSoeeedd8x9991nHMcx//M//2OM4Rh9mo+f3WcMx2qkjLlIGWPMv/zLv5jS0lLj8/nMVVddZXbv3p3uJY2qnTt3GkmfuK1cudIY89Fp6A888IAJhULG7/ebpUuXmsbGxpQ5Tp8+bW699VaTk5NjAoGAuf32201HR0caHs3I6O/4SDJPP/10csy5c+fM3/zN35gpU6aYrKws853vfMecOHEiZZ7f//735vrrrzeTJ082U6dONd///vdNT0/PKD+akfPd737XXHrppcbn85lp06aZpUuXJgNlDMfo01wYKY7VyOBXdQAArDWm3pMCAEwsRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFjr/wMG1vssSZ4VUgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7330804467201233, -1643.4524453536155)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from IPython import display\n",
    "import math\n",
    "\n",
    "\n",
    "class SAC:\n",
    "    class ModelAction(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc_state = torch.nn.Sequential(\n",
    "                torch.nn.Linear(3, 128),\n",
    "                torch.nn.ReLU(),\n",
    "            )\n",
    "            self.fc_mu = torch.nn.Linear(128, 1)\n",
    "            self.fc_std = torch.nn.Sequential(\n",
    "                torch.nn.Linear(128, 1),\n",
    "                torch.nn.Softplus(),\n",
    "            )\n",
    "\n",
    "        def forward(self, state):\n",
    "            #[b, 3] -> [b, 128]\n",
    "            state = self.fc_state(state)\n",
    "\n",
    "            #[b, 128] -> [b, 1]\n",
    "            mu = self.fc_mu(state)\n",
    "\n",
    "            #[b, 128] -> [b, 1]\n",
    "            std = self.fc_std(state)\n",
    "\n",
    "            #根据mu和std定义b个正态分布\n",
    "            dist = torch.distributions.Normal(mu, std)\n",
    "\n",
    "            #采样b个样本\n",
    "            #这里用的是rsample,表示重采样,其实就是先从一个标准正态分布中采样,然后乘以标准差,加上均值\n",
    "            sample = dist.rsample()\n",
    "\n",
    "            #样本压缩到-1,1之间,求动作\n",
    "            action = torch.tanh(sample)\n",
    "\n",
    "            #求概率对数\n",
    "            log_prob = dist.log_prob(sample)\n",
    "\n",
    "            #这个式子看不懂,但参照上下文理解,这个值应该描述的是动作的熵\n",
    "            entropy = log_prob - (1 - action.tanh()**2 + 1e-7).log()\n",
    "            entropy = -entropy\n",
    "\n",
    "            return action * 2, entropy\n",
    "\n",
    "    class ModelValue(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.sequential = torch.nn.Sequential(\n",
    "                torch.nn.Linear(4, 128),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(128, 128),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(128, 1),\n",
    "            )\n",
    "\n",
    "        def forward(self, state, action):\n",
    "            #[b, 3+1] -> [b, 4]\n",
    "            state = torch.cat([state, action], dim=1)\n",
    "\n",
    "            #[b, 4] -> [b, 1]\n",
    "            return self.sequential(state)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_action = self.ModelAction()\n",
    "\n",
    "        self.model_value1 = self.ModelValue()\n",
    "        self.model_value2 = self.ModelValue()\n",
    "\n",
    "        self.model_value_next1 = self.ModelValue()\n",
    "        self.model_value_next2 = self.ModelValue()\n",
    "\n",
    "        self.model_value_next1.load_state_dict(self.model_value1.state_dict())\n",
    "        self.model_value_next2.load_state_dict(self.model_value2.state_dict())\n",
    "\n",
    "        #这也是一个可学习的参数\n",
    "        self.alpha = torch.tensor(math.log(0.01))\n",
    "        self.alpha.requires_grad = True\n",
    "\n",
    "        self.optimizer_action = torch.optim.Adam(\n",
    "            self.model_action.parameters(), lr=3e-4)\n",
    "        self.optimizer_value1 = torch.optim.Adam(\n",
    "            self.model_value1.parameters(), lr=3e-3)\n",
    "        self.optimizer_value2 = torch.optim.Adam(\n",
    "            self.model_value2.parameters(), lr=3e-3)\n",
    "\n",
    "        #alpha也是要更新的参数,所以这里要定义优化器\n",
    "        self.optimizer_alpha = torch.optim.Adam([self.alpha], lr=3e-4)\n",
    "\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).reshape(1, 3)\n",
    "        action, _ = self.model_action(state)\n",
    "        return action.item()\n",
    "\n",
    "    def test(self, play):\n",
    "        #初始化游戏\n",
    "        state = env.reset()\n",
    "\n",
    "        #记录反馈值的和,这个值越大越好\n",
    "        reward_sum = 0\n",
    "\n",
    "        #玩到游戏结束为止\n",
    "        over = False\n",
    "        while not over:\n",
    "            #根据当前状态得到一个动作\n",
    "            action = self.get_action(state)\n",
    "\n",
    "            #执行动作,得到反馈\n",
    "            state, reward, over, _ = env.step([action])\n",
    "            reward_sum += reward\n",
    "\n",
    "            #打印动画\n",
    "            if play and random.random() < 0.2:  #跳帧\n",
    "                display.clear_output(wait=True)\n",
    "                show()\n",
    "\n",
    "        return reward_sum\n",
    "\n",
    "    def _soft_update(self, model, model_next):\n",
    "        for param, param_next in zip(model.parameters(),\n",
    "                                     model_next.parameters()):\n",
    "            #以一个小的比例更新\n",
    "            value = param_next.data * 0.995 + param.data * 0.005\n",
    "            param_next.data.copy_(value)\n",
    "\n",
    "    def _get_target(self, reward, next_state, over):\n",
    "        #首先使用model_action计算动作和动作的熵\n",
    "        #[b, 4] -> [b, 1],[b, 1]\n",
    "        action, entropy = self.model_action(next_state)\n",
    "\n",
    "        #评估next_state的价值\n",
    "        #[b, 4],[b, 1] -> [b, 1]\n",
    "        target1 = self.model_value_next1(next_state, action)\n",
    "        target2 = self.model_value_next2(next_state, action)\n",
    "\n",
    "        #取价值小的,这是出于稳定性考虑\n",
    "        #[b, 1]\n",
    "        target = torch.min(target1, target2)\n",
    "\n",
    "        #exp和log互为反操作,这里是把alpha还原了\n",
    "        #这里的操作是在target上加上了动作的熵,alpha作为权重系数\n",
    "        #[b, 1] - [b, 1] -> [b, 1]\n",
    "        target += self.alpha.exp() * entropy\n",
    "\n",
    "        #[b, 1]\n",
    "        target *= 0.99\n",
    "        target *= (1 - over)\n",
    "        target += reward\n",
    "\n",
    "        return target\n",
    "\n",
    "    def _get_loss_action(self, state):\n",
    "        #计算action和熵\n",
    "        #[b, 3] -> [b, 1],[b, 1]\n",
    "        action, entropy = self.model_action(state)\n",
    "\n",
    "        #使用两个value网络评估action的价值\n",
    "        #[b, 3],[b, 1] -> [b, 1]\n",
    "        value1 = self.model_value1(state, action)\n",
    "        value2 = self.model_value2(state, action)\n",
    "\n",
    "        #取价值小的,出于稳定性考虑\n",
    "        #[b, 1]\n",
    "        value = torch.min(value1, value2)\n",
    "\n",
    "        #alpha还原后乘以熵,这个值期望的是越大越好,但是这里是计算loss,所以符号取反\n",
    "        #[1] - [b, 1] -> [b, 1]\n",
    "        loss_action = -self.alpha.exp() * entropy\n",
    "\n",
    "        #减去value,所以value越大越好,这样loss就会越小\n",
    "        loss_action -= value\n",
    "\n",
    "        return loss_action.mean(), entropy\n",
    "\n",
    "    def _get_loss_value(self, model_value, target, state, action, next_state):\n",
    "        #计算value\n",
    "        value = model_value(state, action)\n",
    "\n",
    "        #计算loss,value的目标是要贴近target\n",
    "        loss_value = self.loss_fn(value, target)\n",
    "        return loss_value\n",
    "\n",
    "    def train(self, state, action, reward, next_state, over):\n",
    "        #对reward偏移,为了便于训练\n",
    "        reward = (reward + 8) / 8\n",
    "\n",
    "        #计算target,这个target里已经考虑了动作的熵\n",
    "        #[b, 1]\n",
    "        target = self._get_target(reward, next_state, over)\n",
    "        target = target.detach()\n",
    "\n",
    "        #计算两个value loss\n",
    "        loss_value1 = self._get_loss_value(self.model_value1, target, state,\n",
    "                                           action, next_state)\n",
    "        loss_value2 = self._get_loss_value(self.model_value2, target, state,\n",
    "                                           action, next_state)\n",
    "\n",
    "        #更新参数\n",
    "        self.optimizer_value1.zero_grad()\n",
    "        loss_value1.backward()\n",
    "        self.optimizer_value1.step()\n",
    "\n",
    "        self.optimizer_value2.zero_grad()\n",
    "        loss_value2.backward()\n",
    "        self.optimizer_value2.step()\n",
    "\n",
    "        #使用model_value计算model_action的loss\n",
    "        loss_action, entropy = self._get_loss_action(state)\n",
    "        self.optimizer_action.zero_grad()\n",
    "        loss_action.backward()\n",
    "        self.optimizer_action.step()\n",
    "\n",
    "        #熵乘以alpha就是alpha的loss\n",
    "        #[b, 1] -> [1]\n",
    "        loss_alpha = (entropy + 1).detach() * self.alpha.exp()\n",
    "        loss_alpha = loss_alpha.mean()\n",
    "\n",
    "        #更新alpha值\n",
    "        self.optimizer_alpha.zero_grad()\n",
    "        loss_alpha.backward()\n",
    "        self.optimizer_alpha.step()\n",
    "\n",
    "        #增量更新next模型\n",
    "        self._soft_update(self.model_value1, self.model_value_next1)\n",
    "        self._soft_update(self.model_value2, self.model_value_next2)\n",
    "\n",
    "\n",
    "teacher = SAC()\n",
    "\n",
    "teacher.train(\n",
    "    torch.randn(5, 3),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 3),\n",
    "    torch.zeros(5, 1).long(),\n",
    ")\n",
    "\n",
    "teacher.get_action([1, 2, 3]), teacher.test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " (tensor([[-0.8575,  0.5145,  1.0999],\n",
       "          [-0.9950, -0.0999,  0.6269],\n",
       "          [-0.9976, -0.0696, -0.3445],\n",
       "          [-0.6277,  0.7784,  0.6930],\n",
       "          [-0.9890,  0.1481,  1.5233],\n",
       "          [-0.9988, -0.0487,  0.6833],\n",
       "          [-0.9976, -0.0687,  0.4000],\n",
       "          [-0.5871,  0.8095, -0.0198],\n",
       "          [-0.7996,  0.6005,  2.0485],\n",
       "          [-0.9924,  0.1227, -0.8042],\n",
       "          [-0.9389, -0.3443, -1.0361],\n",
       "          [-0.9747, -0.2235,  1.3453],\n",
       "          [-0.9992,  0.0389, -0.1037],\n",
       "          [-0.8812, -0.4727, -0.4140],\n",
       "          [-0.9994,  0.0332,  0.1138],\n",
       "          [-0.9921, -0.1254,  0.9562],\n",
       "          [-0.9966,  0.0827, -1.1571],\n",
       "          [-0.9553,  0.2955,  1.5718],\n",
       "          [-0.9772,  0.2125,  0.6995],\n",
       "          [-0.9802,  0.1979, -0.8481],\n",
       "          [-0.9051,  0.4251, -1.5589],\n",
       "          [-0.9016,  0.4325,  0.8630],\n",
       "          [-0.8515,  0.5243, -0.1164],\n",
       "          [-0.9867,  0.1627, -0.4525],\n",
       "          [-0.9631, -0.2692, -3.8166],\n",
       "          [-0.9164, -0.4003,  1.1784],\n",
       "          [-0.9998, -0.0221, -0.5059],\n",
       "          [-0.7957, -0.6057, -3.2072],\n",
       "          [-0.9633, -0.2683,  0.1524],\n",
       "          [-0.9989, -0.0474, -0.2977],\n",
       "          [-0.7906,  0.6124, -0.1057],\n",
       "          [-0.9678,  0.2518, -0.5993],\n",
       "          [-0.9565,  0.2918,  0.2543],\n",
       "          [-0.9913, -0.1320,  1.1274],\n",
       "          [-0.9992,  0.0395, -2.5645],\n",
       "          [-0.8705,  0.4921,  2.5928],\n",
       "          [-0.8857, -0.4643,  0.5935],\n",
       "          [-0.9997, -0.0263, -0.1702],\n",
       "          [-0.8561, -0.5167,  1.2397],\n",
       "          [-0.9960,  0.0896,  1.9079],\n",
       "          [-0.9993, -0.0376, -1.9300],\n",
       "          [-0.9967, -0.0807,  1.5945],\n",
       "          [-0.9995,  0.0331, -0.0119],\n",
       "          [-0.6122,  0.7907, -1.1820],\n",
       "          [-0.9723, -0.2337,  0.1978],\n",
       "          [-0.9934, -0.1150,  0.3033],\n",
       "          [-1.0000, -0.0077, -0.0789],\n",
       "          [-0.9875, -0.1574,  1.5468],\n",
       "          [-0.8712, -0.4908, -0.0139],\n",
       "          [-0.8412, -0.5407,  0.5651],\n",
       "          [-0.9967,  0.0807,  1.3573],\n",
       "          [-0.9995,  0.0325, -0.0253],\n",
       "          [-0.9961, -0.0886, -2.3915],\n",
       "          [-0.9384, -0.3457,  1.2806],\n",
       "          [-0.9691,  0.2465,  0.7200],\n",
       "          [-0.9997,  0.0250, -1.0198],\n",
       "          [-0.9784, -0.2068, -2.0335],\n",
       "          [-0.9774, -0.2113,  0.6331],\n",
       "          [-0.8906,  0.4549,  1.3641],\n",
       "          [-0.9690, -0.2471, -0.2510],\n",
       "          [-0.9355,  0.3534, -1.9717],\n",
       "          [-0.9786, -0.2055,  0.6623],\n",
       "          [-0.9596,  0.2812,  0.2203],\n",
       "          [-0.9740, -0.2266, -0.3349]]),\n",
       "  tensor([[-0.8113],\n",
       "          [-1.6584],\n",
       "          [-0.2475],\n",
       "          [-1.0256],\n",
       "          [-1.8465],\n",
       "          [-1.6452],\n",
       "          [ 1.8562],\n",
       "          [-1.7167],\n",
       "          [ 0.6263],\n",
       "          [ 0.2468],\n",
       "          [ 0.4051],\n",
       "          [ 0.6241],\n",
       "          [ 1.2555],\n",
       "          [-0.4410],\n",
       "          [-0.1230],\n",
       "          [ 0.6760],\n",
       "          [ 1.9394],\n",
       "          [-1.9241],\n",
       "          [-0.0769],\n",
       "          [ 1.2858],\n",
       "          [ 1.6228],\n",
       "          [ 1.2344],\n",
       "          [ 1.5783],\n",
       "          [-0.9580],\n",
       "          [ 0.4859],\n",
       "          [-0.3500],\n",
       "          [ 0.3524],\n",
       "          [-0.5580],\n",
       "          [-0.1233],\n",
       "          [-1.1508],\n",
       "          [ 0.2526],\n",
       "          [-1.6221],\n",
       "          [-1.6859],\n",
       "          [-0.3415],\n",
       "          [ 0.4045],\n",
       "          [-0.4973],\n",
       "          [ 1.1648],\n",
       "          [-1.7503],\n",
       "          [-1.9135],\n",
       "          [-1.0648],\n",
       "          [-1.3230],\n",
       "          [ 0.0849],\n",
       "          [ 1.4892],\n",
       "          [-0.1194],\n",
       "          [ 1.8277],\n",
       "          [-1.1168],\n",
       "          [-0.6951],\n",
       "          [-0.5558],\n",
       "          [-0.2131],\n",
       "          [-1.3633],\n",
       "          [ 1.8358],\n",
       "          [-0.0729],\n",
       "          [-0.7103],\n",
       "          [ 1.0471],\n",
       "          [-1.3690],\n",
       "          [-1.0401],\n",
       "          [-1.3522],\n",
       "          [-1.4203],\n",
       "          [ 0.6526],\n",
       "          [ 1.2774],\n",
       "          [ 0.9853],\n",
       "          [ 1.1388],\n",
       "          [ 1.9253],\n",
       "          [-0.4069]]),\n",
       "  tensor([[ -6.8876],\n",
       "          [ -9.2929],\n",
       "          [ -9.4487],\n",
       "          [ -5.1090],\n",
       "          [ -9.1934],\n",
       "          [ -9.6152],\n",
       "          [ -9.4619],\n",
       "          [ -4.8354],\n",
       "          [ -6.6573],\n",
       "          [ -9.1765],\n",
       "          [ -7.8925],\n",
       "          [ -8.6858],\n",
       "          [ -9.6295],\n",
       "          [ -7.0358],\n",
       "          [ -9.6635],\n",
       "          [ -9.1873],\n",
       "          [ -9.4938],\n",
       "          [ -8.3253],\n",
       "          [ -8.6192],\n",
       "          [ -8.7313],\n",
       "          [ -7.5491],\n",
       "          [ -7.3356],\n",
       "          [ -6.7102],\n",
       "          [ -8.8912],\n",
       "          [ -9.6884],\n",
       "          [ -7.5903],\n",
       "          [ -9.7571],\n",
       "          [ -7.2338],\n",
       "          [ -8.2391],\n",
       "          [ -9.5844],\n",
       "          [ -6.1640],\n",
       "          [ -8.3739],\n",
       "          [ -8.1062],\n",
       "          [ -9.1826],\n",
       "          [-10.2809],\n",
       "          [ -7.5742],\n",
       "          [ -7.1056],\n",
       "          [ -9.7108],\n",
       "          [ -6.9099],\n",
       "          [ -9.6790],\n",
       "          [-10.0090],\n",
       "          [ -9.6230],\n",
       "          [ -9.6652],\n",
       "          [ -5.1109],\n",
       "          [ -8.4506],\n",
       "          [ -9.1692],\n",
       "          [ -9.8224],\n",
       "          [ -9.1408],\n",
       "          [ -6.9093],\n",
       "          [ -6.6402],\n",
       "          [ -9.5564],\n",
       "          [ -9.6667],\n",
       "          [ -9.8924],\n",
       "          [ -7.9415],\n",
       "          [ -8.4204],\n",
       "          [ -9.8185],\n",
       "          [ -9.0195],\n",
       "          [ -8.6194],\n",
       "          [ -7.3120],\n",
       "          [ -8.3713],\n",
       "          [ -8.1206],\n",
       "          [ -8.6569],\n",
       "          [ -8.1683],\n",
       "          [ -8.4969]]),\n",
       "  tensor([[-8.9055e-01,  4.5488e-01,  1.3641e+00],\n",
       "          [-9.9337e-01, -1.1499e-01,  3.0326e-01],\n",
       "          [-9.9885e-01, -4.7949e-02, -4.3380e-01],\n",
       "          [-6.7042e-01,  7.4198e-01,  1.1230e+00],\n",
       "          [-9.9674e-01,  8.0653e-02,  1.3573e+00],\n",
       "          [-9.9764e-01, -6.8678e-02,  4.0002e-01],\n",
       "          [-9.9500e-01, -9.9912e-02,  6.2695e-01],\n",
       "          [-6.0038e-01,  7.9972e-01,  3.2984e-01],\n",
       "          [-8.7054e-01,  4.9210e-01,  2.5928e+00],\n",
       "          [-9.8774e-01,  1.5614e-01, -6.7512e-01],\n",
       "          [-9.5831e-01, -2.8573e-01, -1.2335e+00],\n",
       "          [-9.5855e-01, -2.8493e-01,  1.2713e+00],\n",
       "          [-9.9945e-01,  3.3184e-02,  1.1381e-01],\n",
       "          [-9.0018e-01, -4.3553e-01, -8.3468e-01],\n",
       "          [-9.9963e-01,  2.7174e-02,  1.2025e-01],\n",
       "          [-9.8492e-01, -1.7303e-01,  9.6356e-01],\n",
       "          [-9.9244e-01,  1.2271e-01, -8.0418e-01],\n",
       "          [-9.7485e-01,  2.2288e-01,  1.5048e+00],\n",
       "          [-9.8529e-01,  1.7089e-01,  8.4733e-01],\n",
       "          [-9.7490e-01,  2.2264e-01, -5.0684e-01],\n",
       "          [-8.8283e-01,  4.6969e-01, -9.9666e-01],\n",
       "          [-9.2918e-01,  3.6962e-01,  1.3725e+00],\n",
       "          [-8.6470e-01,  5.0230e-01,  5.1362e-01],\n",
       "          [-9.8255e-01,  1.8600e-01, -4.7424e-01],\n",
       "          [-9.9717e-01, -7.5189e-02, -3.9456e+00],\n",
       "          [-8.9907e-01, -4.3781e-01,  8.2564e-01],\n",
       "          [-1.0000e+00,  1.4010e-03, -4.6955e-01],\n",
       "          [-8.9455e-01, -4.4697e-01, -3.7452e+00],\n",
       "          [-9.6424e-01, -2.6504e-01, -6.7324e-02],\n",
       "          [-9.9976e-01, -2.2075e-02, -5.0586e-01],\n",
       "          [-8.0239e-01,  5.9680e-01,  3.9149e-01],\n",
       "          [-9.5905e-01,  2.8325e-01, -6.5381e-01],\n",
       "          [-9.5964e-01,  2.8123e-01,  2.2029e-01],\n",
       "          [-9.8362e-01, -1.8024e-01,  9.7718e-01],\n",
       "          [-9.8671e-01,  1.6248e-01, -2.4742e+00],\n",
       "          [-9.3228e-01,  3.6174e-01,  2.8873e+00],\n",
       "          [-8.7573e-01, -4.8279e-01,  4.2003e-01],\n",
       "          [-9.9999e-01, -3.7101e-03, -4.5255e-01],\n",
       "          [-8.4120e-01, -5.4072e-01,  5.6513e-01],\n",
       "          [-1.0000e+00, -1.0338e-03,  1.8154e+00],\n",
       "          [-9.9754e-01,  7.0170e-02, -2.1566e+00],\n",
       "          [-9.8753e-01, -1.5744e-01,  1.5468e+00],\n",
       "          [-9.9977e-01,  2.1253e-02,  2.3627e-01],\n",
       "          [-5.8791e-01,  8.0893e-01, -6.0684e-01],\n",
       "          [-9.6874e-01, -2.4807e-01,  2.9668e-01],\n",
       "          [-9.9308e-01, -1.1745e-01,  4.9503e-02],\n",
       "          [-1.0000e+00,  1.7494e-03, -1.8897e-01],\n",
       "          [-9.7471e-01, -2.2346e-01,  1.3453e+00],\n",
       "          [-8.8122e-01, -4.7270e-01, -4.1399e-01],\n",
       "          [-8.4242e-01, -5.3883e-01, -4.4907e-02],\n",
       "          [-9.9999e-01, -3.9197e-03,  1.6932e+00],\n",
       "          [-9.9945e-01,  3.3062e-02, -1.1917e-02],\n",
       "          [-9.9922e-01,  3.9479e-02, -2.5645e+00],\n",
       "          [-9.1637e-01, -4.0033e-01,  1.1784e+00],\n",
       "          [-9.7717e-01,  2.1246e-01,  6.9952e-01],\n",
       "          [-9.9657e-01,  8.2720e-02, -1.1571e+00],\n",
       "          [-9.9607e-01, -8.8618e-02, -2.3915e+00],\n",
       "          [-9.7458e-01, -2.2405e-01,  2.6156e-01],\n",
       "          [-9.2789e-01,  3.7285e-01,  1.8031e+00],\n",
       "          [-9.7195e-01, -2.3519e-01, -2.4467e-01],\n",
       "          [-9.0513e-01,  4.2513e-01, -1.5589e+00],\n",
       "          [-9.7111e-01, -2.3864e-01,  6.7893e-01],\n",
       "          [-9.6914e-01,  2.4650e-01,  7.2000e-01],\n",
       "          [-9.8001e-01, -1.9896e-01, -5.6594e-01]]),\n",
       "  tensor([[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]])))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        #样本池\n",
    "        self.datas = []\n",
    "\n",
    "    #向样本池中添加N条数据,删除M条最古老的数据\n",
    "    def update_data(self, agent):\n",
    "        #初始化游戏\n",
    "        state = env.reset()\n",
    "\n",
    "        #玩到游戏结束为止\n",
    "        over = False\n",
    "        while not over:\n",
    "            #根据当前状态得到一个动作\n",
    "            action = agent.get_action(state)\n",
    "\n",
    "            #执行动作,得到反馈\n",
    "            next_state, reward, over, _ = env.step([action])\n",
    "\n",
    "            #记录数据样本\n",
    "            self.datas.append((state, action, reward, next_state, over))\n",
    "\n",
    "            #更新游戏状态,开始下一个动作\n",
    "            state = next_state\n",
    "\n",
    "        #数据上限,超出时从最古老的开始删除\n",
    "        while len(self.datas) > 100000:\n",
    "            self.datas.pop(0)\n",
    "\n",
    "    #获取一批数据样本\n",
    "    def get_sample(self):\n",
    "        #从样本池中采样\n",
    "        samples = random.sample(self.datas, 64)\n",
    "\n",
    "        #[b, 3]\n",
    "        state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 3)\n",
    "        #[b, 1]\n",
    "        action = torch.FloatTensor([i[1] for i in samples]).reshape(-1, 1)\n",
    "        #[b, 1]\n",
    "        reward = torch.FloatTensor([i[2] for i in samples]).reshape(-1, 1)\n",
    "        #[b, 3]\n",
    "        next_state = torch.FloatTensor([i[3] for i in samples]).reshape(-1, 3)\n",
    "        #[b, 1]\n",
    "        over = torch.LongTensor([i[4] for i in samples]).reshape(-1, 1)\n",
    "\n",
    "        return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "data = Data()\n",
    "\n",
    "data.update_data(teacher), data.get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1191.669590342427\n",
      "10 -1155.2899091132763\n",
      "20 -1612.6655150976717\n",
      "30 -1357.096313048631\n",
      "40 -349.71248661166544\n",
      "50 -700.6887568917681\n",
      "60 -823.3950230099035\n",
      "70 -731.2046245584472\n",
      "80 -144.5438052028179\n",
      "90 -111.65458076799659\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    #更新N条数据\n",
    "    data.update_data(teacher)\n",
    "\n",
    "    #每次更新过数据后,学习N次\n",
    "    for i in range(200):\n",
    "        teacher.train(*data.get_sample())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        test_result = sum([teacher.test(play=False) for _ in range(10)]) / 10\n",
    "        print(epoch, test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.7815548181533813, -1513.1286141790065)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CQL(SAC):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _get_loss_value(self, model_value, target, state, action, next_state):\n",
    "        #计算value\n",
    "        value = model_value(state, action)\n",
    "\n",
    "        #计算loss,value的目标是要贴近target\n",
    "        loss_value = self.loss_fn(value, target)\n",
    "        \"\"\"以上与SAC相同,以下是CQL的部分\"\"\"\n",
    "\n",
    "        #把state复制5遍\n",
    "        state = state.unsqueeze(dim=1)\n",
    "        state = state.repeat(1, 5, 1).reshape(-1, 3)\n",
    "\n",
    "        #把next_state复制5遍\n",
    "        #[b, 3] -> [b, 1, 3]\n",
    "        next_state = next_state.unsqueeze(1)\n",
    "        #[b, 1, 3] -> [b, 5, 3] -> [b*5, 3]\n",
    "        next_state = next_state.repeat(1, 5, 1).reshape(-1, 3)\n",
    "\n",
    "        #随机一批动作,数量是数据量的5倍,值域在-1到1之间\n",
    "        rand_action = torch.empty([len(state), 1]).uniform_(-1, 1)\n",
    "\n",
    "        #计算state的动作和熵\n",
    "        #[b*5, 3] -> [b*5, 1],[b*5, 1]\n",
    "        curr_action, curr_entropy = self.model_action(state)\n",
    "\n",
    "        #计算next_state的动作和熵\n",
    "        #[b*5, 3] -> [b*5, 1],[b*5, 1]\n",
    "        next_action, next_entropy = self.model_action(next_state)\n",
    "\n",
    "        #计算三份动作分别的value\n",
    "        #[b*5, 1],[b*5, 1] -> [b*5, 1] -> [b, 5, 1]\n",
    "        value_rand = model_value(state, rand_action).reshape(-1, 5, 1)\n",
    "        #[b*5, 1],[b*5, 1] -> [b*5, 1] -> [b, 5, 1]\n",
    "        value_curr = model_value(state, curr_action).reshape(-1, 5, 1)\n",
    "        #[b*5, 1],[b*5, 1] -> [b*5, 1] -> [b, 5, 1]\n",
    "        value_next = model_value(state, next_action).reshape(-1, 5, 1)\n",
    "\n",
    "        #[b*5, 1] -> [b, 5, 1]\n",
    "        curr_entropy = curr_entropy.detach().reshape(-1, 5, 1)\n",
    "        next_entropy = next_entropy.detach().reshape(-1, 5, 1)\n",
    "\n",
    "        #三份value分别减去他们的熵\n",
    "        #[b, 5, 1]\n",
    "        value_rand -= math.log(0.5)\n",
    "        #[b, 5, 1]\n",
    "        value_curr -= curr_entropy\n",
    "        #[b, 5, 1]\n",
    "        value_next -= next_entropy\n",
    "\n",
    "        #拼合三份value\n",
    "        #[b, 5+5+5, 1] -> [b, 15, 1]\n",
    "        value_cat = torch.cat([value_rand, value_curr, value_next], dim=1)\n",
    "\n",
    "        #等价t.logsumexp(dim=1), t.exp().sum(dim=1).log()\n",
    "        #[b, 15, 1] -> [b, 1] -> scala\n",
    "        loss_cat = torch.logsumexp(value_cat, dim=1).mean()\n",
    "\n",
    "        #在原本的loss上增加上这一部分\n",
    "        #scala\n",
    "        loss_value += 5.0 * (loss_cat - value.mean())\n",
    "        \"\"\"CQL算法和SCA算法的差异到此为止\"\"\"\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "\n",
    "student = CQL()\n",
    "\n",
    "student.train(\n",
    "    torch.randn(5, 3),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 1),\n",
    "    torch.randn(5, 3),\n",
    "    torch.zeros(5, 1).long(),\n",
    ")\n",
    "\n",
    "student.get_action([1, 2, 3]), student.test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OHoSU6uI-xIt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1311.025866669426\n",
      "2000 -912.0954630884487\n",
      "4000 -381.1426011292569\n",
      "6000 -475.7436788080395\n",
      "8000 -571.308119324903\n",
      "10000 -557.3846798710574\n",
      "12000 -351.51184253246527\n",
      "14000 -737.5261783022646\n",
      "16000 -533.6833954872317\n",
      "18000 -419.3709548261987\n",
      "20000 -666.2548385709767\n",
      "22000 -734.8301856097612\n",
      "24000 -885.9918666290581\n",
      "26000 -551.6000112476158\n",
      "28000 -560.0620483852484\n",
      "30000 -933.4139934630114\n",
      "32000 -360.8237455410657\n",
      "34000 -833.4917443377905\n",
      "36000 -260.9713534856566\n",
      "38000 -800.5712740533719\n",
      "40000 -373.75356499111786\n",
      "42000 -757.2715911544987\n",
      "44000 -731.975856719401\n",
      "46000 -828.5287536989603\n",
      "48000 -522.9316518671445\n"
     ]
    }
   ],
   "source": [
    "#训练N次,训练过程中不需要更新数据\n",
    "for i in range(50000):\n",
    "    #采样一批数据\n",
    "    student.train(*data.get_sample())\n",
    "\n",
    "    if i % 2000 == 0:\n",
    "        test_result = sum([student.test(play=False) for _ in range(10)]) / 10\n",
    "        print(i, test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-486.2209349178763"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
